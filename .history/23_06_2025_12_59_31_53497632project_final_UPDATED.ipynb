{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873c49ef-1ee4-40b7-9653-104517bb28e1",
   "metadata": {},
   "source": [
    "# Predicting Usage of a Video Game Research Server\n",
    "### Student Name: Vitor Han \n",
    "\n",
    "### Student Number: 53497632"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c7cbc-6051-428c-a00f-a4693f3c356b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In collaboration with a UBC Computer Science research group, this project explores behavioral patterns of players on a Minecraft research server. The server records each player’s activity to understand player engagement, data contribution, and predict demand. Accurately predicting these factors helps the research team allocate server resources, target recruitment strategies, and improve player experience.\n",
    "\n",
    "I selected Question 1 of the broad questions and use it to formulate a specific question using some of the variables in the dataset.\n",
    "\n",
    "**Question:**  Can a player's gender predict their likelihood of subscribing to a game-related newsletter, and does this relationship differ between novice (\"Beginner\") and experienced (\"Pro\") players?\n",
    "\n",
    "\n",
    "**Link to github repository:** https://github.com/vitxrlee/dsci-100-2025SS1-project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624fc97-e899-4ea0-ae74-d601dabc2e44",
   "metadata": {},
   "source": [
    "## Data Description \n",
    "\n",
    "The dataset consists of two files:\n",
    "\n",
    "- players.csv: Contains demographic and gameplay-related features for each player (e.g., player ID, total play time, play frequency, and whether they subscribed to the newsletter).\n",
    "\n",
    "- sessions.csv: Includes logs of each play session per player (e.g., session start/end, actions performed, duration).\n",
    "\n",
    "### Summary of dataset:\n",
    "\n",
    "**sessions.csv (each row represents one gameplay session and includes):**\n",
    "\n",
    "- hashedEmail: useless in our project\n",
    "\n",
    "- start_time: The human-readable start time of the session.\n",
    "\n",
    "- end_time: The human-readable end time of the session.\n",
    "\n",
    "- original_start_time: Start time in Unix timestamp format.\n",
    "\n",
    "- original_end_time: End time in Unix timestamp format.\n",
    "\n",
    "\n",
    "**players.csv (each row in this dataset indicates an individual player):**\n",
    "\n",
    "- experience: Self-reported gaming experience, categorized as Beginner, Amateur, Regular, Veteran, or Pro.\n",
    "\n",
    "- subscribe: Indicating whether the player subscribed to the server’s content or notifications.\n",
    "\n",
    "- hashedEmail: A pseudonymized identifier for each player.\n",
    "\n",
    "- played_hours: Total number of hours the player has played on the server.\n",
    "\n",
    "- name: The first name of the player.\n",
    "\n",
    "- gender: Gender identity (Male, Female, Non-binary).\n",
    "\n",
    "- age: The player’s self-reported age (integer).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d867c-a449-4725-8161-afc2269c927a",
   "metadata": {},
   "source": [
    "## Methods & Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa7c41-5d52-468d-86a0-bf795d2f09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(yardstick)\n",
    "\n",
    "# Download data\n",
    "player_url <- \"https://raw.githubusercontent.com/vitxrlee/dsci-100-2025SS1-project/refs/heads/main/players.csv\"  \n",
    "session_url <- \"https://raw.githubusercontent.com/vitxrlee/dsci-100-2025SS1-project/refs/heads/main/sessions.csv\"\n",
    "\n",
    "# Save locally\n",
    "download.file(player_url, destfile = \"players.csv\")\n",
    "download.file(session_url, destfile = \"sessions.csv\")\n",
    "\n",
    "# Read data\n",
    "players <- read_csv(\"players.csv\") \n",
    "sessions <- read_csv(\"sessions.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68cf42-6d8d-4911-8ce3-03a77db556cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simplify gender variable\n",
    "players <- players |> \n",
    "  mutate(\n",
    "      gender_simple = ifelse(\n",
    "        gender == \"Male\", \"Male\",\n",
    "        ifelse(gender == \"Female\", \"Female\", \"Other\")\n",
    "      )\n",
    "  )\n",
    "\n",
    "# Filter only Beginner and Pro players\n",
    "players_filtered <- players |> \n",
    "  filter(experience %in% c(\"Beginner\", \"Pro\")) |> \n",
    "  mutate(\n",
    "    subscribe = as.factor(subscribe),\n",
    "    experience = factor(experience, levels = c(\"Beginner\", \"Pro\")),\n",
    "    gender_simple = as.factor(gender_simple)\n",
    "  )\n",
    "\n",
    "# Table of gender & subscribe\n",
    "gender_experience_subscribe <- players_filtered |> \n",
    "  group_by(gender_simple, experience, subscribe) |> \n",
    "  summarize(count = n(), .groups = \"drop\") # removes grouping after summarizing. References in the bottom of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813512ad-62c0-42be-bd61-a040296fa6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for each group\n",
    "ggplot(gender_experience_subscribe, aes(x = subscribe, y = count, fill = gender_simple)) +\n",
    "  geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "  facet_wrap(~experience) + #creates separate plots for each experience level. References in the bottom of the page\n",
    "  labs(\n",
    "    title = \"Newsletter Subscription by Gender and Experience\",\n",
    "    x = \"Subscription Status\", \n",
    "    y = \"Player Count\", \n",
    "    fill = \"Gender\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b73fbf-25ac-4a9e-8605-92231c211a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2025)\n",
    "data_split <- initial_split(players_filtered, prop = 0.7, strata = subscribe)\n",
    "train_data <- training(data_split)\n",
    "test_data <- testing(data_split)\n",
    "\n",
    "# Recipe\n",
    "knn_recipe <- recipe(subscribe ~ gender_simple + experience, data = train_data) |>\n",
    "  step_dummy(all_nominal_predictors()) |> # Check references in the bottom of the page\n",
    "  step_zv(all_predictors()) # Check references in the bottom of the page\n",
    "\n",
    "# Model specification\n",
    "knn_model <- nearest_neighbor(neighbors = 5) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Workflow\n",
    "knn_workflow <- workflow() |>\n",
    "  add_model(knn_model) |>\n",
    "  add_recipe(knn_recipe)\n",
    "\n",
    "# Fit model\n",
    "knn_fit <- fit(knn_workflow, data = train_data)\n",
    "\n",
    "# Predict\n",
    "knn_predictions <- predict(knn_fit, test_data, type = \"prob\") |> \n",
    "  bind_cols(predict(knn_fit, test_data)) |>\n",
    "  bind_cols(test_data)\n",
    "\n",
    "# The type = \"prob\" option returns class probabilities for classification models. Check references in the bottom of the page\n",
    "\n",
    "# Metrics\n",
    "metrics(knn_predictions, truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "# Visualization\n",
    "ggplot(knn_predictions, aes(x = .pred_TRUE, fill = subscribe)) +\n",
    "  geom_histogram(position = \"identity\", bins = 30) +\n",
    "  labs(\n",
    "    title = \"k-NN Predicted Probability of Subscribing\",\n",
    "    x = \"Predicted Probability\",\n",
    "    y = \"Number of Players\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897507d4-4527-4915-ab41-7627f019a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "conf_mat(knn_predictions, truth = subscribe, estimate = .pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c850ca9-5d90-401b-b5a4-59473654c753",
   "metadata": {},
   "source": [
    "### Confusion Matrix Analysis\n",
    "\n",
    "The confusion matrix below provides deeper insight into how well the k-NN model performed in classifying players who subscribed to the newsletter versus those who did not.\n",
    "\n",
    "- **True Positives (TP)**: Players who subscribed and were correctly predicted as subscribers. → **9**\n",
    "- **True Negatives (TN)**: Players who did not subscribe and were correctly predicted as non-subscribers. → **1**\n",
    "- **False Positives (FP)**: Players who did not subscribe but were predicted as subscribers (Type I error). → **3**\n",
    "- **False Negatives (FN)**: Players who subscribed but were predicted as non-subscribers (Type II error). → **3**\n",
    "\n",
    "This matrix helps identify whether the model is biased towards predicting a specific class and informs potential improvements in feature selection or model tuning.\n",
    "\n",
    "From the confusion matrix, we can derive additional performance metrics like:\n",
    "\n",
    "- **Accuracy**: Overall correctness of the model.  \n",
    "- **Precision** = TP / (TP + FP) = 9 / (9 + 3) = **0.75** — important when the cost of false positives is high.  \n",
    "- **Recall** = TP / (TP + FN) = 9 / (9 + 3) = **0.75** — important when missing true positives is costly.  \n",
    "- **F1 Score**: Harmonic mean of precision and recall, useful when classes are imbalanced.\n",
    "\n",
    "Based on this analysis, we can better understand how well our model generalizes to unseen data, and whether it's appropriate for deployment in targeting players likely to subscribe.\n",
    "\n",
    "**Calculated Metrics:**\n",
    "\n",
    "- **True Positives (TP)** = 9  \n",
    "- **True Negatives (TN)** = 1  \n",
    "- **False Positives (FP)** = 3  \n",
    "- **False Negatives (FN)** = 3  \n",
    "\n",
    "- **Precision** = TP / (TP + FP) = 9 / (9 + 3) = **0.75**  \n",
    "- **Recall** = TP / (TP + FN) = 9 / (9 + 3) = **0.75**  \n",
    "\n",
    "These values show that the model performs equally well in terms of identifying true subscribers (recall) and maintaining a relatively low false positive rate (precision).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73306e-7c82-4d49-8115-e7288fc9ee31",
   "metadata": {},
   "source": [
    "## Data Analysis \n",
    "\n",
    "### Why is this method appropriate?\n",
    "The k-Nearest Neighbors (k-NN) classification method is appropriate because the goal of the project is to predict whether a player subscribes to a game-related newsletter—a binary classification task. k-NN is a simple, flexible, and non-parametric model that does not assume any particular distribution of the input features. It works well with categorical variables (after they are properly encoded), making it suitable for our use of gender and experience. Furthermore, k-NN is useful for detecting local structure in the data, which is important for understanding how player traits might relate to subscription behavior.\n",
    "\n",
    "### Which assumptions are required, if any, to apply the method selected?\n",
    "Although k-NN is non-parametric and does not assume linearity or normality, it still relies on a few practical assumptions. The most important assumption is that the features used to compute distances are meaningful and on comparable scales. In our case, since gender and experience are categorical, I used one-hot encoding to convert them into numeric dummy variables. Another assumption is that similar players will have similar outcomes, which is implicit in how k-NN makes predictions based on nearest neighbors.\n",
    "\n",
    "### What are the potential limitations or weaknesses of the method selected?\n",
    "One major limitation of k-NN is that it can be sensitive to irrelevant or uninformative features. Since it relies on distance measures, including too many predictors or having poorly scaled variables can degrade performance. Additionally, k-NN can become computationally expensive as the dataset grows, though this is not a problem in our relatively small dataset. Another key limitation is that k-NN does not produce interpretable coefficients like logistic regression does, which makes it less suitable if I want to understand the exact effect of each predictor.\n",
    "\n",
    "### How did you compare and select the model?\n",
    "I selected k-NN classification as a simple and intuitive baseline model for our binary outcome. It serves as a good alternative to logistic regression when we want to explore whether prediction can be made using proximity-based similarity. I used a default of 5 neighbors (k = 5), which is a commonly recommended starting point. Although I did not tune k in this project, i could use cross-validation in future work to find the optimal value. This model allows me to test whether gender and experience level alone contain enough information to predict subscription behavior.\n",
    "\n",
    "###  How are you going to process the data to apply the model?\n",
    "To prepare the data for k-NN classification, I first filtered the dataset to include only players with either \"Beginner\" or \"Pro\" experience levels. I also simplified the gender variable into three categories: Male, Female, and Other. Because k-NN requires numeric input, I applied one-hot encoding using step_dummy() to convert the categorical variables into binary indicator columns. I split the data into training and testing sets using initial_split() with a 70/30 proportion and stratified by the subscribe variable to preserve the class balance. The k-NN model was then trained on the training data, and predictions were evaluated using the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60455214-5596-4ec0-97f2-ea541dd0beca",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "In this project, I used a k-Nearest Neighbors (k-NN) classification model to predict whether a player subscribed to a game-related newsletter based on their gender and experience level. After filtering the data to include only “Beginner” and “Pro” players, and simplifying the gender variable, I trained a model using one-hot encoded predictors. The results showed moderate predictive accuracy, indicating that gender and experience do carry some information about a player's likelihood of subscribing, but are not highly strong predictors on their own.\n",
    "\n",
    "This result was somewhat expected. I anticipated that more experienced players might be more engaged and therefore more likely to subscribe, and that gender might play a minor role in shaping engagement behavior. However, the overall performance of the model suggests that these two variables alone are not sufficient to make highly accurate predictions, which aligns with the idea that player engagement is likely influenced by a wider range of behavioral and personal factors.\n",
    "\n",
    "These findings have practical implications for how recruitment and communication strategies could be designed. If certain gender-experience combinations are more or less likely to subscribe, outreach materials can be better tailored. However, care should be taken not to overgeneralize based on limited predictors, especially when the model’s predictive power is only moderate.\n",
    "\n",
    "Future work could expand this analysis by including additional variables such as play time, session frequency, or interaction with the server. These behavioral metrics might provide more nuanced insight into who is likely to subscribe. It would also be valuable to explore other classification models or apply cross-validation to tune k and improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b8ddb-dd6b-4f77-9739-769f63e1220d",
   "metadata": {},
   "source": [
    "## APA Style References: \n",
    "\n",
    "Kuhn, M., & Wickham, H. (2024). step_dummy: _Create dummy variables from categorical predictors_. tidymodels. https://recipes.tidymodels.org/reference/step_dummy.html\n",
    "\n",
    "Kuhn, M., & Vaughan, D. (2024). parsnip: _A tidy, unified interface to models_ (Version 1.2.0). https://parsnip.tidymodels.org/reference/predict.model_fit.html\n",
    "\n",
    "Kuhn, M., & Wickham, H. (2024). step_zv: _Remove variables with zero variance_. tidymodels. https://recipes.tidymodels.org/reference/step_zv.html\n",
    "\n",
    "Wickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2024). dplyr: A Grammar of Data Manipulation (Version 1.1.4). Posit Software, PBC. https://dplyr.tidyverse.org/reference/summarise.html\n",
    "\n",
    "Wickham, H., et al. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics (Version 3.4.4) [R package]. The Comprehensive R Archive Network (CRAN). https://ggplot2.tidyverse.org/reference/facet_wrap.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16184f3",
   "metadata": {},
   "source": [
    "\n",
    "### Model Results Visualization\n",
    "\n",
    "I visualized the predicted probabilities using histograms, separated by subscription status. This allowed me to inspect how well the model distinguishes between players who subscribe and those who do not. The histogram shows that predicted probabilities for \"TRUE\" subscription cluster higher for actual subscribers, which suggests the model captures signal in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8695f84",
   "metadata": {},
   "source": [
    "\n",
    "### Model Performance\n",
    "\n",
    "The model’s accuracy, precision, and recall values (see metrics output) indicate that it performs moderately well. The class imbalance and feature simplicity may limit performance, but the results still provide useful insights.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
